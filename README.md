# EmbodiedAgentSim

A comprehensive framework for benchmarking embodied AI agents using Habitat-Lab. Supports 58+ benchmark tasks including Object Navigation, Point Navigation, Image Navigation, Rearrangement, and Multi-Agent scenarios with integrated video recording capabilities.

## ğŸ¯ Features

- **58+ Benchmark Tasks**: Navigation, rearrangement, multi-agent scenarios
- **Video Recording**: Automatic episode recording with configurable output
- **Interactive Mode**: Real-time navigation testing and demonstration  
- **Modular Architecture**: Easy agent integration and task customization
- **Habitat-Lab Integration**: Full compatibility with Habitat ecosystem

## ğŸ“¦ Installation

```bash
# Clone repository
git clone https://github.com/yourusername/EmbodiedAgentSim.git
cd EmbodiedAgentSim

# Create environment  
conda env create -f environment.yml
conda activate habitat

# Install package
pip install -e .
```

## ğŸš€ Quick Start

### List Available Tasks
```bash
# See all 58+ available benchmark tasks
easim list-tasks
```

### Run Benchmarks
```bash
# Object Navigation
easim benchmark --task objectnav_hm3d --episodes 10
easim benchmark --task objectnav_mp3d --episodes 10 --record

# Embodied Question Answering
easim benchmark --task eqa_hm3d --episodes 10
easim benchmark --task eqa_rgbonly_hm3d --episodes 5 --record

# Express-Bench (Rich trajectory data - 2044 episodes)
easim benchmark --task eqa_hm3d_express --episodes 20 --record
easim benchmark --task eqa_rgbonly_hm3d_express --episodes 15
```

### Interactive Demo
```bash
# Run interactive navigation demo
easim interactive
```

## ğŸ“‹ Available Benchmark Categories

### Tuned and Ready Tasks

#### Object Navigation
- **ObjectNav HM3D**: `objectnav_hm3d`, `objectnav_hm3d_with_semantic`
- **ObjectNav MP3D**: `objectnav_mp3d`, `objectnav_mp3d_with_semantic`

#### Embodied Question Answering
- **Standard EQA**: `eqa_hm3d`, `eqa_rgbonly_hm3d` (500 episodes)
- **Express-Bench**: `eqa_hm3d_express`, `eqa_rgbonly_hm3d_express` (2044 episodes with rich trajectory data)

### Additional Available Tasks (Not Yet Tuned)
- Point Navigation, Image Navigation, VLN, Rearrangement, Multi-Agent tasks
- Use `easim list-tasks` to see all 58+ available benchmarks

## ğŸ›  Python API

### Basic Benchmarking
```python
from easim.benchmark.benchmark import HabitatBenchmark
from easim.agents.sample import SampleAgent

# Initialize benchmark and agent
benchmark = HabitatBenchmark("objectnav_hm3d")
agent = SampleAgent()

# Run evaluation
metrics = benchmark.evaluate(agent, num_episodes=10)
print(f"Success Rate: {metrics['success']:.3f}")

# With video recording
metrics = benchmark.evaluate(agent, num_episodes=5, record_video=True)
```

### Video Recording
```python
from easim.utils.video_recorder import VideoRecorder
from pathlib import Path

# Setup video directory
video_dir = VideoRecorder.setup_video_directory("my_task")

# Record single episode with video
env = benchmark._env
metrics = VideoRecorder.record_episode_with_video(
    env, agent, episode_num=0, video_dir=video_dir
)

# Record without video (faster)
metrics = VideoRecorder.record_episode_no_video(env, agent)
```

### Custom Agent Integration
```python
from habitat import Agent

class MyAgent(Agent):
    def reset(self):
        pass
    
    def act(self, observations):
        # Your agent logic here
        return {"action": "move_forward"}

# Use with benchmark
agent = MyAgent()
benchmark = HabitatBenchmark("pointnav_hm3d")
results = benchmark.evaluate(agent, num_episodes=10)
```

## ğŸ“ Project Structure

```
EmbodiedAgentSim/
â”œâ”€â”€ easim/
â”‚   â”œâ”€â”€ agents/                 # Agent implementations
â”‚   â”‚   â””â”€â”€ sample.py          # Sample random agent
â”‚   â”œâ”€â”€ benchmark/             # Benchmarking framework
â”‚   â”‚   â””â”€â”€ benchmark.py       # HabitatBenchmark class
â”‚   â”œâ”€â”€ cli/                   # Command line interface
â”‚   â”‚   â”œâ”€â”€ commands.py        # Command handlers
â”‚   â”‚   â””â”€â”€ parser.py          # Argument parsing
â”‚   â”œâ”€â”€ evaluation/            # Evaluation metrics and analysis
â”‚   â”œâ”€â”€ examples/              # Usage examples
â”‚   â”‚   â”œâ”€â”€ interactive.py     # Interactive demo
â”‚   â”‚   â””â”€â”€ video.py          # Video recording example
â”‚   â””â”€â”€ utils/                 # Utilities and constants
â”‚       â”œâ”€â”€ constants.py       # Benchmark configs and paths
â”‚       â”œâ”€â”€ video_recorder.py  # Video recording functionality
â”‚       â””â”€â”€ habitat_utils.py   # Habitat-lab setup
â”œâ”€â”€ data/                      # Auto-created data directory
â”‚   â””â”€â”€ output/               # Benchmark results and videos
â””â”€â”€ habitat-lab/              # Habitat-lab submodule
```

## ğŸ® Command Reference

### Core Commands
| Command | Description | Example |
|---------|-------------|---------|
| `list-tasks` | Show all available benchmark tasks | `easim list-tasks` |
| `interactive` | Run interactive navigation demo | `easim interactive` |
| `benchmark` | Run agent benchmarking | `easim benchmark --task objectnav_hm3d` |

### Benchmark Options
| Option | Description | Default | Example |
|--------|-------------|---------|---------|
| `--task` | Benchmark task to run | `objectnav_hm3d` | `--task pointnav_mp3d` |
| `--episodes` | Number of episodes | `10` | `--episodes 5` |
| `--record` | Enable video recording | `False` | `--record` |
| `--agent` | Agent type | `sample` | `--agent custom` |

## ğŸ“Š Output and Results

### Benchmark Metrics
Results include standard Habitat-Lab metrics:
- **Success Rate**: Episode completion percentage
- **SPL**: Success weighted by Path Length
- **Distance to Goal**: Final distance to target
- **Episode Length**: Steps taken per episode

### Video Output
When `--record` is enabled:
- Videos saved to: `data/output/videos/{task_name}/run_001/`
- Format: `episode_001.mp4`, `episode_002.mp4`, etc.
- Automatic run numbering prevents overwrites

## ğŸ”§ Advanced Usage

### Custom Benchmark Configuration
```python
# Access all available benchmarks
from easim.utils.constants import BENCHMARK_CONFIG

print(f"Available tasks: {len(BENCHMARK_CONFIG)}")
for task, config_path in BENCHMARK_CONFIG.items():
    print(f"{task}: {config_path}")
```

### Batch Evaluation
```bash
# Run multiple ObjectNav and EQA tasks
for task in objectnav_hm3d objectnav_mp3d eqa_hm3d eqa_hm3d_express; do
    easim benchmark --task $task --episodes 10 --record
done
```

## ğŸ“š Dataset Requirements

The framework requires Habitat-Lab datasets. Refer to [Habitat-Lab documentation](https://github.com/facebookresearch/habitat-lab) for dataset setup:

- **Scene Datasets**: HM3D, MP3D, Gibson, HSSD, ProcTHOR
- **Task Datasets**: ObjectNav, PointNav, ImageNav, Rearrangement
- **Installation**: Follow Habitat-Lab dataset installation guide

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Implement your changes
4. Add tests and documentation
5. Submit a pull request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file.

## ğŸ™ Acknowledgments

Built on top of [Habitat-Lab](https://github.com/facebookresearch/habitat-lab) by Facebook AI Research.